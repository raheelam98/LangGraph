{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raheelam98/LangGraph/blob/main/fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lang Chain and Lang Graph Fundaments"
      ],
      "metadata": {
        "id": "4ZNnlaeQzczv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install the required packages\n",
        "%%capture --no-stderr\n",
        "%pip install -U langgraph langsmith langchain_google_genai"
      ],
      "metadata": {
        "id": "TkbypbwLTQ4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84jg4r-M9d-R"
      },
      "outputs": [],
      "source": [
        "# API Keys\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "# os.environ[\"LANGCHAIN_PROJECT\"] = \"quickstart\"\n",
        "\n",
        "gemini_api_key = userdata.get('GEMINI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    max_retries=2,\n",
        "    api_key=gemini_api_key\n",
        ")"
      ],
      "metadata": {
        "id": "Grnz1quKTuFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check llm is working\n",
        "result = llm.invoke(\"hi\")\n",
        "result"
      ],
      "metadata": {
        "id": "FbUjjZnIT4j3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tutorials**\n",
        "\n",
        "[How-to Guides - LangGraph](https://langchain-ai.github.io/langgraph/how-tos/)\n"
      ],
      "metadata": {
        "id": "F7qHbQdlUy-7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Module 1\n",
        "\n",
        "[Module 1 - GitHub](https://github.com/panaversity/learn-applied-generative-ai-fundamentals/tree/main/03_langchain_ecosystem/langgraph/course-notebooks/module-1)\n",
        "\n",
        "[Q3,Q4,Q5 - Class -14: LangGraph - Six steps to create a graph : Agentic Architecture - Oct 17, 2024](https://www.youtube.com/watch?v=7U_9hCE3Prs)"
      ],
      "metadata": {
        "id": "IDWwoRVkVCSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3_router.ipynb**\n",
        "\n",
        "**`Tool calling`**: Utilizes a chat model API that handles tool schemas and messages, producing tool invocations as output.\n",
        "\n",
        "**`ToolNode`** Usage: ToolNode, a LangChain Runnable, processes graph state (with messages) and updates state with tool call results, seamlessly integrating with LangGraph's ReAct agent or any StateGraph with MessagesState.\n",
        "\n",
        "ToolNode: Takes a list of functions and stores them within the tool node.\n",
        "\n",
        "When any value is stored in it, ToolNode makes it runnable, calls it to perform the functionality, and provides the response\n",
        "\n",
        "ToolNode == Runable\n",
        "\n",
        "```bash\n",
        "from langgraph.prebuilt import ToolNode # special node for function calls\n",
        "from langgraph.prebuilt import tools_condition # either call tool oe end\n",
        "\n",
        "from langgraph.graph import MessagesState\n",
        "\n",
        "\n",
        "# Build graph\n",
        "builder: StateGraph = StateGraph(MessagesState)\n",
        "\n",
        "graph_builder.add_node(\"tools\", ToolNode([multiply]))\n",
        "```\n",
        "\n",
        "**rm note**\n",
        "\n",
        "**`ToolNode`** is a built-in function of LangGraph. We can create our own custom function that provides a list of tools such as a search engine, Excel file operations, weather search, or database search in SQL. To integrate these tools into LangGraph, pass them into a custom `ToolNode`. We’ll build our own `BasicToolNode` and replace LangGraph’s prebuilt `ToolNode` and `tools_condition` with it, using\n",
        "\n",
        "ToolNode(tools=[your_tool]).\n",
        "\n",
        "**ToolNode** is essentially a node within a workflow or graph that is designated to execute a specific tool or function when called.\n",
        "\n",
        "**ToolNode** is a LangChain Runnable that takes graph state (with a list of messages) as input and outputs state update with the result of tool calls.\n",
        "\n",
        "**ToolNode** is just a class that helps with this execution. You pass it your list of tools, and internally it stores them as name-function pairs."
      ],
      "metadata": {
        "id": "8qOajYdGzl4p"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IIelF1kIWHZI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}